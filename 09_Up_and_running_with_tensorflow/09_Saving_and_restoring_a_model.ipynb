{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存と復元\n",
    "# モデルをほかのプログラムで使用したり、比較するために使う。\n",
    "# 訓練中に適宜保存することでクラッシュ後のリラン対応も行える\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import os\n",
    "\n",
    "# reset_graph用メソッド\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "# m : housing.data.shape の行が設定される　20640\n",
    "# n : housing.data.shape の列が設定される  8\n",
    "\n",
    "# housing.data : データの中身を見れる(多次元配列)\n",
    "# hoousing.data.shape : 配列の定義を見れる ここでは(20640,8) 20640インスタンス、特徴量8個"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配降下法はスケーリングが重要なのでまずはスケーリングを行う。手法はお任せ。ここではscikit-learnで実施する\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data) # housing.data を指定してスケーリングを行う\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "# np.ones((m, 1)) : [1.]の20640個の配列\n",
    "# np.c_ : 行列の連結\n",
    "# np.c_[np.ones((m, 1)), housing.data] : [1., housing.dataの特徴量(8個)] の20640インスタンスのnumpy配列が出来上がる\n",
    "# 先頭にバイアスとして　１　が設定されるnumpy配列ができているということ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.161543\n",
      "Epoch 100 MSE = 0.7145006\n",
      "Epoch 200 MSE = 0.566705\n",
      "Epoch 300 MSE = 0.5555719\n",
      "Epoch 400 MSE = 0.5488112\n",
      "Epoch 500 MSE = 0.5436362\n",
      "Epoch 600 MSE = 0.5396294\n",
      "Epoch 700 MSE = 0.5365092\n",
      "Epoch 800 MSE = 0.5340678\n",
      "Epoch 900 MSE = 0.5321474\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000                                                                       # not shown in the book\n",
    "learning_rate = 0.01                                                                  # not shown\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            # not shown\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            # not shown\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "# random_uniform : 与えた形状と範囲に基づいてランダム値を格納するテンソルを生成する\n",
    "# tf.random_uniform([n + 1, 1]) では (9,1)のnumpy配列　ここでは操作名\"theata\" として(9,1)のnumpy配列 最小値-1,最大値1 で作成\n",
    "# theataが重みをもった特徴量ベクトルになる\n",
    "\n",
    "#y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "# tf.matmul : 行列積  ここでは訓練データ(20640,9)と(9,1)の行列積となる python 3.5 からは以下の書き方がある\n",
    "# ここで行列積を出しているのは入力となるnumpy配列の特徴量ベクトルと重み更新のためのtheata特徴量ベクトルをかけることにより予測値を出すため\n",
    "#python3.5からの簡単な記載\n",
    "y_pred = X @ theta\n",
    "error = y_pred - y                                                                    # not shown\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    # not shown\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)            # not shown\n",
    "training_op = optimizer.minimize(mse)                                                 # not shown\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "# 構築フェーズの最後にSaverノードを作成する\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())                                # not shown\n",
    "            save_path = saver.save(sess, \"C:/Users/leuyx/Documents/ml/09_model/my_model.ckpt\") #　モデルを保存したいタイミングでsave()メソッドを実行する\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"C:/Users/leuyx/Documents/ml/09_model/my_model_final.ckpt\") # 最終的に作成されたモデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614528 ],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/leuyx/Documents/ml/09_model/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "# モデルの復元は構築フェーズの最後でSaverを作っておき、実行フェーズにinitノードを使うのではなく、restoreメソッドを呼んで復元させる\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"C:/Users/leuyx/Documents/ml/09_model/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval() # not shown in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored) # これはリストア前後の配列が同じか比較している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この機能を使うことで事前学習済みのモデルを使うことができる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
